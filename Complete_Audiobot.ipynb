{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "L1UIguU1yxYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from speech_recognition import AudioFile, Recognizer\n",
        "\n",
        "def stt(audio: object, language: str) -> str:\n",
        "    \"\"\"Converts speech to text.\n",
        "\n",
        "    Args:\n",
        "        audio: record of user speech\n",
        "\n",
        "    Returns:\n",
        "        text (str): recognized speech of user\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a Recognizer object\n",
        "    r = Recognizer()\n",
        "    # Open the audio file\n",
        "    with AudioFile(audio) as source:\n",
        "        # Listen for the data (load audio to memory)\n",
        "        audio_data = r.record(source)\n",
        "        # Transcribe the audio using Google's speech-to-text API\n",
        "        text = r.recognize_google(audio_data, language=language)\n",
        "    return text"
      ],
      "metadata": {
        "id": "a_7CK3lNy4rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "def tts(text: str, language: str) -> object:\n",
        "    \"\"\"Converts text into audio object.\n",
        "\n",
        "    Args:\n",
        "        text (str): generated answer of bot\n",
        "\n",
        "    Returns:\n",
        "        object: text to speech object\n",
        "    \"\"\"\n",
        "    return gTTS(text=text, lang=language, slow=False)"
      ],
      "metadata": {
        "id": "YyHoLOjb1tnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "\n",
        "def tts_to_bytesio(tts_object: object) -> bytes:\n",
        "    \"\"\"Converts tts object to bytes.\n",
        "\n",
        "    Args:\n",
        "        tts_object (object): audio object obtained from gtts\n",
        "\n",
        "    Returns:\n",
        "        bytes: audio bytes\n",
        "    \"\"\"\n",
        "    bytes_object = BytesIO()\n",
        "    tts_object.write_to_fp(bytes_object)\n",
        "    bytes_object.seek(0)\n",
        "    return bytes_object.getvalue()"
      ],
      "metadata": {
        "id": "bOnkoHfh2Zqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import b64encode\n",
        "\n",
        "def html_audio_autoplay(bytes: bytes) -> object:\n",
        "    \"\"\"Creates html object for autoplaying audio at gradio app.\n",
        "\n",
        "    Args:\n",
        "        bytes (bytes): audio bytes\n",
        "\n",
        "    Returns:\n",
        "        object: html object that provides audio autoplaying\n",
        "    \"\"\"\n",
        "    b64 = b64encode(bytes).decode()\n",
        "    html = f\"\"\"\n",
        "    <audio controls autoplay>\n",
        "    <source src=\"data:audio/wav;base64,{b64}\" type=\"audio/wav\">\n",
        "    </audio>\n",
        "    \"\"\"\n",
        "    return html"
      ],
      "metadata": {
        "id": "uM_IyK3v3Nvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio import Audio, Interface, Textbox\n",
        "import langchain\n",
        "import openai\n",
        "import os\n",
        "\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "o6u0I83C4njm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "chat_model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")\n",
        "conversation = ConversationChain(llm=chat_model)"
      ],
      "metadata": {
        "id": "BS1cMmuF56PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(audio: object):\n",
        "    \"\"\"Calls functions for deploying gradio app.\n",
        "\n",
        "    It responds both verbally and in text\n",
        "    by taking voice input from user.\n",
        "\n",
        "    Args:\n",
        "        audio (object): recorded speech of user\n",
        "\n",
        "    Returns:\n",
        "        tuple containing\n",
        "\n",
        "        - user_speech_text (str) : recognized speech\n",
        "        - bot_response_de (str) : translated answer of bot\n",
        "        - html (object) : autoplayer for bot's speech\n",
        "    \"\"\"\n",
        "    desired_language = \"de\"\n",
        "    user_speech_text = stt(audio, desired_language)\n",
        "    #print(user_speech_text)\n",
        "    bot_response_de = conversation.run(user_speech_text)\n",
        "    #print(\"\\n\"+bot_response_de)\n",
        "    bot_voice = tts(bot_response_de, desired_language)\n",
        "    bot_voice_bytes = tts_to_bytesio(bot_voice)\n",
        "    html = html_audio_autoplay(bot_voice_bytes)\n",
        "    return user_speech_text, bot_response_de, html"
      ],
      "metadata": {
        "id": "KUPd6sKG4pJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Interface(\n",
        "    fn=main,\n",
        "    inputs=[\n",
        "        Audio(\n",
        "            source=\"microphone\",\n",
        "            type=\"filepath\",\n",
        "        ),\n",
        "    ],\n",
        "    outputs=[\n",
        "        Textbox(label=\"Sie sagen: \"),\n",
        "        Textbox(label=\"KI antwort: \"),\n",
        "        \"html\",\n",
        "    ],\n",
        "    live=True,\n",
        "    allow_flagging=\"never\",\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "0bHQS1ou6Y_y",
        "outputId": "95bf091c-238b-424a-a311-877fc90f4671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hint: Set streaming=True for Audio component to use live streaming.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "\n",
            "Setting up a public link... we have recently upgraded the way public links are generated. If you encounter any problems, please report the issue and downgrade to gradio version 3.13.0\n",
            ".\n",
            "Running on public URL: https://6ca84447-3d3a-47ab.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6ca84447-3d3a-47ab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory"
      ],
      "metadata": {
        "id": "K9J71NQ59sua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "46d89221-8309-4b89-a07e-18c19675ab37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4a85f75ac4cc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconversation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'conversation' is not defined"
          ]
        }
      ]
    }
  ]
}